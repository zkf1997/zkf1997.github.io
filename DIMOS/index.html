<!DOCTYPE html>
<html lang="en">
   <head>
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
      <meta name="description" content="DIMOS">
       <meta name="keywords" content="human-scene interaction synthesis">
      <meta name="author" content="Kaifeng Zhao">
      <title>DIMOS: Synthesizing Diverse Human Motions in 3D Indoor Scenes</title>

      <!--<meta property="og:title" content="EgoBody: ..." />-->
      <!--<meta property="og:description" content="EgoBody is a ... ">-->
      <!--<meta property="og:image" content="images/teaser.jpg" />-->

      <!--<meta name="twitter:card" content="summary_large_image" />-->
      <!--<meta name="twitter:title" content="EgoBody: ..." />-->
      <!--<meta name="twitter:description" content="EgoBody is a ..." />-->
      <!--<meta name="twitter:image" content="https://neuralbodies.github.io/LEAP/images/teaser1200x630.jpg" />-->
      <!--<meta name="twitter:image:alt" content="EgoBody" />-->

      <!-- Bootstrap core CSS -->
      <link href="vendor/bootstrap/css/bootstrap.min.css" rel="stylesheet">
      <!-- Custom styles for this template -->
      <link href="css/scrolling-nav.css" rel="stylesheet">
      <!-- nice figures  -->
      <link rel="stylesheet" href="css/font-awesome.css">
      <link rel="icon" type="image/png" href="images/icon.png">
      
      <style>
         .video-container-2x2 {
           display: grid;
           grid-template-columns: repeat(2, 1fr);
           grid-gap: 10px; /* Adjust the gap between videos */
         }
         
         .video-container-2x2 video {
           width: 100%; /* Adjust the width as needed */
         }

         .video-container-2 {
            display: flex;
            justify-content: space-between;
         }
         
         .video-container-2 video {
            width: 48%; /* Adjust the width as needed */
         }

         .caption-container {
            display: flex;
            justify-content: space-between;
            margin-top: 10px; /* Adjust the margin as needed */
         }
         
         .caption {
            width: 48%; /* Adjust the width as needed */
            text-align: center;
         }

         .video-container {
            display: flex;
            justify-content: center;
            align-items: center;
         }
  
       </style>
   </head>
   <body id="page-top">
      <!-- Navigation -->
      <nav class="navbar navbar-expand-lg navbar-dark bg-dark fixed-top" id="mainNav">
         <div class="container">
            <a class="navbar-brand js-scroll-trigger" href="#page-top">DIMOS</a>
            <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarResponsive" aria-controls="navbarResponsive" aria-expanded="false" aria-label="Toggle navigation">
            <span class="navbar-toggler-icon"></span>
            </button>
            <div class="collapse navbar-collapse" id="navbarResponsive">
               <ul class="navbar-nav ml-auto">
                  <li class="nav-item">
                     <a class="nav-link js-scroll-trigger" href="#about">Overview</a>
                  </li>
                  <!-- <li class="nav-item">
                     <a class="nav-link js-scroll-trigger" href="#demo">Demo</a>
                  </li> -->
                  <li class="nav-item">
                     <a class="nav-link js-scroll-trigger" href="#video">Video</a>
                  </li>
                  <li class="nav-item">
                     <a class="nav-link js-scroll-trigger" href="#method">Method</a>
                  </li>
                  <!-- <li class="nav-item">
                     <a class="nav-link js-scroll-trigger" href="#dataset">Dataset</a>
                  </li> -->
                  
                  <li class="nav-item">
                     <a class="nav-link js-scroll-trigger" href="#results">Results</a>
                  </li>      
                  
                  <li class="nav-item">
                     <a class="nav-link js-scroll-trigger" href="#citation">Citation</a>
                  </li>

                  <!-- <li class="nav-item">
                     <a class="nav-link js-scroll-trigger" href="#related_projects">Related Projects</a>
                  </li> -->
                  <!-- <li class="nav-item">
                     <a class="nav-link js-scroll-trigger" href="#team">Team</a>
                  </li> -->
               </ul>
            </div>
         </div>
      </nav>


      <header class="bg-light text-black">
          <div class="container text-center">
             <h1>DIMOS</h1>
             <h2>Synthesizing Diverse Human Motions in 3D Indoor Scenes</h2><br>
              <div id="content">
          <div id="content-inner">

            <div class="section head">

                <div class="authors">
                    <h5>
                        <a href="https://vlg.inf.ethz.ch/team/Kaifeng-Zhao.html">Kaifeng Zhao</a><sup>1</sup>&nbsp;
                        <a href="https://vlg.inf.ethz.ch/team/Dr-Yan-Zhang.html">Yan Zhang</a><sup>1</sup>&nbsp;
                        <a href="https://vlg.inf.ethz.ch/team/Shaofei-Wang.html">Shaofei Wang</a><sup>1</sup>&nbsp;
                        <a href="https://thabobeeler.com/">Thabo Beeler</a><sup>2</sup>&nbsp;
                        <a href="https://vlg.inf.ethz.ch/team/Prof-Dr-Siyu-Tang.html">Siyu Tang</a><sup>1</sup>
                        <h5>
                </div>

                <div class="affiliations">
                    <h5>
                        <sup>1</sup><a href="https://ethz.ch/en.html">ETH ZÃ¼rich</a>&nbsp; &nbsp;&nbsp;
                        <sup>2</sup><a href="https://arvr.google.com/">Google</a> &nbsp;&nbsp;
                        <h5>
                </div>

                <div class="venue"><h5>ICCV 2023<h5></div>

                <div class="downloads">
                    <br><h3>
                    <a class="publink" href="https://arxiv.org/abs/2305.12411" target="_blank" style="text-decoration: none"> ArXiv <i class="fa fa-print"></i></a> &nbsp;
                    &nbsp;&nbsp;
                    <a class="publink" href="https://github.com/zkf1997/DIMOS" target="_blank" style="text-decoration: none"> Code <i class="fa fa-github"></i></a>
                    <h3>
                </div>

            </div>


            <!-- <br> -->


        </div>
      </header>


      <section id="about" class="about-section">
         <div class="container">
            <div class="row">
               <div class="col-lg-10 mx-auto">

                  <br><br>
                  <h2>Overview</h2>
                  <p class="lead text-justify">
                     In this work, we propose a method to generate a sequence of natural human-scene interaction events in real-world complex scenes as illustrated in this figure.
The human first walks to sit on a stool (<font color="#CCCC00">yellow</font> to <font color="#DC143C">red</font>), then walk to another chair to sit down (<font color="#DC143C">red</font> to <font color="#8B008B">magenta</font>), and finally
walk to and lie on the sofa (<font color="#8B008B">magenta</font> to <font color="#1E90FF">blue</font>).
                  </p>
                 
                  <p><img class="img-fluid" alt="teaser" width="100%" src="images/teaser_canonical.png"></p>
               </div>
            </div>
         </div>
      </section>

      <section id="method" class="method-section">
         <div class="container">
            <div class="row">
               <div class="col-lg-10 mx-auto">
                  <br>
                  <h2>Method</h2>
                  <p class="lead text-justify">
                     We formulate synthesizing human behaviors in 3D scenes as a Markov decision process with a latent action space, which is learned from motion capture datasets.
                     We train scene-aware and goal-driven agent policies to synthesize various human behaviors in indoor scenes including wandering in the room, sitting or lying on an object, and sequential combinations of these actions.
                  </p>
                  <!-- <figure>
                     <video class="centered" width="100%" controls="" muted="" loop="" autoplay="">
                         <source src="videos/mp_model.mp4" type="video/mp4">
                     </video>
                 </figure>
                  <p class="lead text-justify">
                     Illustration of the motion primitive generative model that generates future motions conditioned on the history motions.                  
                  </p>
                  <figure>
                     <video class="centered" width="100%" controls="" muted="" loop="" autoplay="">
                         <source src="videos/mp_recursive.mp4" type="video/mp4">
                     </video>
                 </figure>
                  <p class="lead text-justify">
                     Illustration of generating random but perpetual motions by recursively sampling the learned motion primitive model.
                  </p> -->
                  <br>
                  <br>
                  <p><img class="img-fluid" alt="pipeline" width="100%" src="images/overview.png"></p>
                  <p class="lead text-justify">
                     Illustration of our proposed human-scene interaction synthesis framework, which consists of learned motion primitive (actions), alongside locomotion and interaction policies generating latent actions conditioned on scenes and interaction goals. 
                     By integrating navigation mesh-based path-finding and static human-scene interaction generation methods, we can synthesize realistic motion sequences for virtual humans with fine-grained controls.
                  </p>
                  <br>
                  <br>
                  <p><img class="img-fluid" alt="pipeline" width="100%" src="images/locomotion_policy.png"></p>
                  <p class="lead text-justify">
                     Illustration of the scene-aware locomotion policy network. 
                     The locomotion policy state consists of the body markers, the goal-reaching feature of normalized direction vectors from markers to the goal pelvis, 
                     and the interaction feature of a 2D binary map indicating the walkability (<font color="#DC143C">red</font>: non-walkable area, <font color="#1E90FF">blue</font>: walkable area) of the local 1.6m * 1.6m square area. 
                     The locomotion policy network employs the actor-critic architecture and shares the state encoder.
                     
                  </p>
                  <br>
                  <br>
                  <p><img class="img-fluid" alt="pipeline" width="100%" src="images/interaction_policy.png"></p>
                  <p class="lead text-justify">
                     Illustration of the object interaction policy network. The interaction policy state consists of the body markers, the goal-reaching features of both distance and direction from current markers to the goal markers, and the interaction features of the signed distances from each marker to the object surfaces and the signed distance gradient at each marker location.  Such interaction features encode the human-object proximity relationship.
                  </p>
                  
               </div>
            </div>
         </div>
      </section>

      <section id="video" class="video-section">
         <div class="container">
            <div class="row">
               <div class="col-lg-10 mx-auto">
                  <h2 class="section-title-tc">Video</h2>
                  <div class="embed-responsive embed-responsive-16by9">
                    <iframe class="embed-responsive-item" src="https://www.youtube.com/embed/O3VpvETNjcw" title="DIMOS" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>
                  </div>
                  
               </div>
            </div>
         </div>
      </section>

      <section id="results" class="">
         <div class="container">
            <div class="row">
               <div class="col-lg-10 mx-auto">
                  <h2 class="section-title-tc">Results</h2>
                  <!-- <figure>
                     <video class="centered" width="100%" controls="" muted="" loop="" autoplay="">
                         <source src="videos/inhabit.mp4" type="video/mp4">
                     </video>
                 </figure>
                 <br> -->

                 <p class="lead text-justify">
                  Our method generalize to novel objects and real world scenes.
                  </p>
                 <div class="video-container-2x2">
                        <video class="centered" width="50%" controls="" muted="" loop="" autoplay="">
                           <source src="videos/chair_1.mp4" type="video/mp4">
                        </video>
                     
                        <video class="centered" width="50%" controls="" muted="" loop="" autoplay="">
                           <source src="videos/chair_2.mp4" type="video/mp4">
                        </video>
                  <!-- </div>
                  <div class="video-container"> -->
                        <video class="centered" width="50%" controls="" muted="" loop="" autoplay="">
                           <source src="videos/chair_3.mp4" type="video/mp4">
                        </video>
                        
                        <video class="centered" width="50%" controls="" muted="" loop="" autoplay="">
                           <source src="videos/chair_4.mp4" type="video/mp4">
                        </video>
                  </div>
                  <p class="lead text-center">
                     Sitting on a novel chair with unique shape and low height.
                  </p>
                  <br>

                  <p class="lead text-justify">
                     Inhabiting reconstructed scenes.
                  </p>
                  <div class="video-container-2">
                   
                     <video class="centered" width="100%" controls="" muted="" loop="" autoplay="">
                        <source src="videos/paris_1.mp4" type="video/mp4">
                     </video>
                   
                     <video class="centered" width="100%" controls="" muted="" loop="" autoplay="">
                        <source src="videos/paris_2.mp4" type="video/mp4">
                     </video>
                                
                  </div>
                  <p class="lead text-center">
                     Walking to sit on a bus stop bench in a Paris street point cloud from <a href="https://npm3d.fr/paris-carla-3d">Paris-CARLA-3D</a>.
                  </p>
                  <br>
                  
                  <div class="video-container">
                     <video class="centered" width="50%" controls="" muted="" loop="" autoplay="">
                        <source src="videos/MPH8_new.mp4" type="video/mp4">
                     </video>
                  </div>
                  <p class="lead text-center">
                     Walking to sit on a bed in a reconstructed room from <a href="https://prox.is.tue.mpg.de/">PROX</a>.
                  </p>
                  <br>
                  
                  <p class="lead text-justify">
                     Interaction with unusual-shaped objects generated by <a href="https://github.com/openai/shap-e">text-to-3D method Shap-E </a>.
                  </p>
                  <div class="video-container-2">
                     <video class="centered" width="100%" controls="" muted="" loop="" autoplay="">
                        <source src="videos/avacado_0.mp4" type="video/mp4">
                     </video>
                   
                     <video class="centered" width="100%" controls="" muted="" loop="" autoplay="">
                        <source src="videos/avacado_2.mp4" type="video/mp4">
                     </video>
                  </div>
                  <p class="lead text-center">
                     Sit on avacado-shaped chairs.
                  </p>
                  <div class="video-container-2">
                     <video class="centered" width="100%" controls="" muted="" loop="" autoplay="">
                        <source src="videos/dog_1.mp4" type="video/mp4">
                     </video>
                   
                     <video class="centered" width="100%" controls="" muted="" loop="" autoplay="">
                        <source src="videos/dog_3.mp4" type="video/mp4">
                     </video>
                  </div>
                  <p class="lead text-center">
                     Sit on dog-shaped chairs.
                  </p>
                  <br>
                  <br>

                  <p class="lead text-justify">
                     Policy learning process.
                  </p>
                  <div class="video-container-2">
                     <video class="centered" width="100%" controls="" muted="" loop="" autoplay="">
                        <source src="videos/learn_0.mp4" type="video/mp4">
                     </video>
                   
                     <video class="centered" width="100%" controls="" muted="" loop="" autoplay="">
                        <source src="videos/learn_50.mp4" type="video/mp4">
                     </video>
                  </div>
                  <div class="caption-container">
                     <div class="caption">Epoch 0, move randomly and ignore sitting</div>
                     <div class="caption">Epoch 50, learned to move to the chair </div>
                  </div>
                  <br>

                  <div class="video-container-2">
                     <video class="centered" width="100%" controls="" muted="" loop="" autoplay="">
                        <source src="videos/learn_100.mp4" type="video/mp4">
                     </video>
                   
                     <video class="centered" width="100%" controls="" muted="" loop="" autoplay="">
                        <source src="videos/learn_1000.mp4" type="video/mp4">
                     </video>
                  </div>
                  <div class="caption-container">
                     <div class="caption">Epoch 100, learned to sit</div>
                     <div class="caption">Epoch 1000, can sit more naturally </div>
                  </div>
                  <br>
                  <br>
                  

                  <p class="lead text-justify">
                     Limitations.
                  </p>
                  <div class="video-container-2">
                     <video class="centered" width="100%" controls="" muted="" loop="" autoplay="">
                        <source src="videos/penetration_1.mp4" type="video/mp4">
                     </video>
                   
                     <video class="centered" width="100%" controls="" muted="" loop="" autoplay="">
                        <source src="videos/penetration_2.mp4" type="video/mp4">
                     </video>
                  </div>
                  <p class="lead text-center">
                     As a kinematics-based method, human-scene penetration remains observable in synthesis results.
                  </p>
                  <br>

                  <div class="video-container-2">
                     <video class="centered" width="100%" controls="" muted="" loop="" autoplay="">
                        <source src="videos/lie_1.mp4" type="video/mp4">
                     </video>
                   
                     <video class="centered" width="100%" controls="" muted="" loop="" autoplay="">
                        <source src="videos/lie_2.mp4" type="video/mp4">
                     </video>
                  </div>
                  <p class="lead text-center">
                     Insufficient training motion data for lying leads to degraded motion results with unnatural poses. 
                  </p>
                  <br>
                  <br>

                  <p class="lead text-justify">
                     Comparison with more related works.
                  </p>
                  <div class="video-container-2">
                   
                        <video class="centered" width="100%" controls="" muted="" loop="" autoplay="">
                           <source src="videos/MPH16_long.mp4" type="video/mp4">
                        </video>
                      
                        <video class="centered" width="100%" controls="" muted="" loop="" autoplay="">
                           <source src="videos/MPH16_our.mp4" type="video/mp4">
                        </video>
                                   
                  </div>
                  <div class="caption-container">
                     <div class="caption"><a href="https://jiashunwang.github.io/Long-term-Motion-in-3D-Scenes/">[46]</a></div>
                     <div class="caption">Ours</div>
                   </div>
                  <br>

                  <div class="video-container-2">
                     <video class="centered" width="100%" controls="" muted="" loop="" autoplay="">
                        <source src="videos/chair0_couch.mp4" type="video/mp4">
                     </video>
                   
                     <video class="centered" width="100%" controls="" muted="" loop="" autoplay="">
                        <source src="videos/chair0_our.mp4" type="video/mp4">
                     </video>
                  </div>
                  <div class="caption-container">
                     <div class="caption"><a href="https://virtualhumans.mpi-inf.mpg.de/couch/">COUCH [50]</a></div>
                     <div class="caption">Ours</div>
                  </div>

                  <!-- <div class="video-container-2">
                     <video class="centered" width="100%" controls="" muted="" loop="" autoplay="">
                        <source src="videos/chair7_couch.mp4" type="video/mp4">
                     </video>
                   
                     <video class="centered" width="100%" controls="" muted="" loop="" autoplay="">
                        <source src="videos/chair7_our.mp4" type="video/mp4">
                     </video>
                  </div>
                  <div class="caption-container">
                     <div class="caption"><a href="https://virtualhumans.mpi-inf.mpg.de/couch/">COUCH [50]</a></div>
                     <div class="caption">Ours</div>
                  </div> -->

               </div>
            </div>
         </div>
      </section>

      <section id="citation" class="">
         <div class="container">
            <div class="row">
               <div class="col-lg-10 mx-auto">
                  <h2 class="section-title-tc">Citation</h2>
                  <!-- <br> -->
                  <!-- <a class="publink" target="_blank" href="https://arxiv.org/pdf/2112.07642.pdf"><b>
                    EgoBody: Human Body Shape and Motion of Interacting People from Head-Mounted Devices </b><br></a>
                    Siwei Zhang, Qianli Ma, Yan Zhang, Zhiyin Qian, Taein Kwon, Marc Pollefeys, Federica Bogo, Siyu Tang<br>
                  <br><br> -->
<pre style="display: block; background-color: #f5f5f5; border: 1px solid #ccc; border-radius: 4px">
@inproceedings{Zhao:ICCV:2023,
   title = {Synthesizing Diverse Human Motions in 3D Indoor Scenes},
   author = {Zhao, Kaifeng and Zhang, Yan and Wang, Shaofei and Beeler, Thabo and Tang, Siyu},
   booktitle = {International conference on computer vision (ICCV)},
   year = {2023}
}</pre>
         <h2>Related Projects</h2>
         <p class="lead text-justify">
         This project is developed on top of prior works, please also consider citing the following projects:
         </p>

<a href="https://yz-cnsdqz.github.io/eigenmotion/GAMMA/">GAMMA: The Wanderings of Odysseus in 3D Scenes</a>
<pre style="display: block; background-color: #f5f5f5; border: 1px solid #ccc; border-radius: 4px">
@inproceedings{zhang2022wanderings,
   title={The Wanderings of Odysseus in 3D Scenes},
   author={Zhang, Yan and Tang, Siyu},
   booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
   pages={20481--20491},
   year={2022}
}</pre>

<a href="https://zkf1997.github.io/COINS/index.html">COINS: Compositional Human-Scene Interaction Synthesis with Semantic Control</a>
<pre style="display: block; background-color: #f5f5f5; border: 1px solid #ccc; border-radius: 4px">
   @inproceedings{Zhao:ECCV:2022,
   title = {Compositional Human-Scene Interaction Synthesis with Semantic Control},
   author = {Zhao, Kaifeng and Wang, Shaofei and Zhang, Yan and Beeler, Thabo and Tang, Siyu},
   booktitle = {European conference on computer vision (ECCV)},
   year = {2022}
}</pre>
               </div>
            </div>
         </div>
      </section>

      <!-- <section id="related_projects" class="">
         <div class="container">
            <div class="row">
               <div class="col-lg-10 mx-auto">
	              
                    
               </div>
            </div>
         </div>
      </section> -->

      <section id="contact" class="">
         <div class="container">
            <div class="row">
               <div class="col-lg-10 mx-auto">
	                <h2>Contact</h2>
		            <br>For questions, please contact Kaifeng Zhao:<br><a href="mailto:kaifeng.zhao@inf.ethz.ch">kaifeng.zhao@inf.ethz.ch</a>
               </div>
            </div>
         </div>
      </section>

      <!-- Footer -->
      <footer class="py-5 bg-dark">
         <div class="container">
            <p class="m-0 text-center text-white">Copyright &copy; VLG 2023</p>
             <p style="text-align:right;font-size:small;" class="text-white">
            template from <a href="https://neuralbodies.github.io/LEAP/index.html">LEAP</a>
         </div>
         <!-- /.container -->
      </footer>
      <!-- Bootstrap core JavaScript -->
      <script src="vendor/jquery/jquery.min.js"></script>
      <script src="vendor/bootstrap/js/bootstrap.bundle.min.js"></script>
      <!-- Plugin JavaScript -->
      <script src="vendor/jquery-easing/jquery.easing.min.js"></script>
      <!-- Custom JavaScript for this theme -->
      <script src="js/scrolling-nav.js"></script>
   </body>
</html>
